# CIFAR-10 DATASET
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Un-J-iqvLmOK",
        "outputId": "fb523a7e-171f-41b8-8de3-4b06a300baaa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:02<00:00, 72458512.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n",
            "Epoch [1/10], Loss: 1.5957\n",
            "Epoch [2/10], Loss: 1.2011\n",
            "Epoch [3/10], Loss: 0.9951\n",
            "Epoch [4/10], Loss: 0.8775\n",
            "Epoch [5/10], Loss: 0.8095\n",
            "Epoch [6/10], Loss: 0.7506\n",
            "Epoch [7/10], Loss: 0.7057\n",
            "Epoch [8/10], Loss: 0.6773\n",
            "Epoch [9/10], Loss: 0.6494\n",
            "Epoch [10/10], Loss: 0.6243\n",
            "Accuracy of the model on the test images: 75.60%\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    airplane       0.76      0.82      0.79      1000\n",
            "  automobile       0.94      0.79      0.86      1000\n",
            "        bird       0.69      0.66      0.68      1000\n",
            "         cat       0.58      0.58      0.58      1000\n",
            "        deer       0.68      0.80      0.73      1000\n",
            "         dog       0.76      0.58      0.66      1000\n",
            "        frog       0.89      0.74      0.81      1000\n",
            "       horse       0.75      0.81      0.78      1000\n",
            "        ship       0.77      0.91      0.84      1000\n",
            "       truck       0.79      0.87      0.83      1000\n",
            "\n",
            "    accuracy                           0.76     10000\n",
            "   macro avg       0.76      0.76      0.75     10000\n",
            "weighted avg       0.76      0.76      0.75     10000\n",
            "\n",
            "Model saved to cnn_cifar10.pth\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn.functional as F\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "])\n",
        "\n",
        "\n",
        "train_dataset = torchvision.datasets.CIFAR10(\n",
        "    root='./data', train=True, download=True, transform=transform)\n",
        "test_dataset = torchvision.datasets.CIFAR10(\n",
        "    root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=2)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=2)\n",
        "\n",
        "\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.fc1 = nn.Linear(128 * 4 * 4, 256)\n",
        "        self.fc2 = nn.Linear(256, 128)\n",
        "        self.fc3 = nn.Linear(128, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = self.pool(F.relu(self.conv3(x)))\n",
        "        x = x.view(-1, 128 * 4 * 4)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "model = CNN().to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "\n",
        "def train_model(num_epochs=10):\n",
        "    model.train()\n",
        "    for epoch in range(num_epochs):\n",
        "        running_loss = 0.0\n",
        "        for images, labels in train_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {running_loss / len(train_loader):.4f}')\n",
        "\n",
        "\n",
        "def evaluate_model():\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "            all_preds.extend(predicted.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    print(f'Accuracy of the model on the test images: {100 * correct / total:.2f}%')\n",
        "\n",
        "\n",
        "    print(\"\\nClassification Report:\")\n",
        "    print(classification_report(all_labels, all_preds, target_names=test_dataset.classes))\n",
        "\n",
        "\n",
        "def save_model(path='cnn_cifar10.pth'):\n",
        "    torch.save(model.state_dict(), path)\n",
        "    print(f'Model saved to {path}')\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    train_model(num_epochs=10)\n",
        "    evaluate_model()\n",
        "    save_model()\n"
      ]
    },
# CIFAR-100 DATASET
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn.functional as F\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "])\n",
        "\n",
        "train_dataset = torchvision.datasets.CIFAR100(\n",
        "    root='./data', train=True, download=True, transform=transform)\n",
        "test_dataset = torchvision.datasets.CIFAR100(\n",
        "    root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=2)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=2)\n",
        "\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.fc1 = nn.Linear(128 * 4 * 4, 256)\n",
        "        self.fc2 = nn.Linear(256, 128)\n",
        "        self.fc3 = nn.Linear(128, 100)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = self.pool(F.relu(self.conv3(x)))\n",
        "        x = x.view(-1, 128 * 4 * 4)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "model = CNN().to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "\n",
        "def train_model(num_epochs=10):\n",
        "    model.train()\n",
        "    for epoch in range(num_epochs):\n",
        "        running_loss = 0.0\n",
        "        for images, labels in train_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {running_loss / len(train_loader):.4f}')\n",
        "\n",
        "\n",
        "def evaluate_model():\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "            all_preds.extend(predicted.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    print(f'Accuracy of the model on the CIFAR-100 test images: {100 * correct / total:.2f}%')\n",
        "\n",
        "    print(\"\\nClassification Report:\")\n",
        "    print(classification_report(all_labels, all_preds, target_names=test_dataset.classes))\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    train_model(num_epochs=10)\n",
        "    evaluate_model()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UZH3cHVYghlH",
        "outputId": "e0ca22f9-7173-466d-d7c7-404194f75954"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz to ./data/cifar-100-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 169001437/169001437 [00:02<00:00, 76256044.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-100-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n",
            "Epoch [1/10], Loss: 3.9714\n",
            "Epoch [2/10], Loss: 3.4066\n",
            "Epoch [3/10], Loss: 3.0795\n",
            "Epoch [4/10], Loss: 2.8616\n",
            "Epoch [5/10], Loss: 2.6854\n",
            "Epoch [6/10], Loss: 2.5535\n",
            "Epoch [7/10], Loss: 2.4492\n",
            "Epoch [8/10], Loss: 2.3569\n",
            "Epoch [9/10], Loss: 2.2794\n",
            "Epoch [10/10], Loss: 2.2234\n",
            "Accuracy of the model on the CIFAR-100 test images: 38.90%\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "        apple       0.65      0.73      0.69       100\n",
            "aquarium_fish       0.41      0.54      0.47       100\n",
            "         baby       0.30      0.23      0.26       100\n",
            "         bear       0.22      0.19      0.21       100\n",
            "       beaver       0.29      0.16      0.21       100\n",
            "          bed       0.41      0.26      0.32       100\n",
            "          bee       0.43      0.52      0.47       100\n",
            "       beetle       0.53      0.35      0.42       100\n",
            "      bicycle       0.44      0.45      0.44       100\n",
            "       bottle       0.58      0.51      0.54       100\n",
            "         bowl       0.19      0.08      0.11       100\n",
            "          boy       0.48      0.14      0.22       100\n",
            "       bridge       0.50      0.42      0.46       100\n",
            "          bus       0.32      0.28      0.30       100\n",
            "    butterfly       0.31      0.36      0.33       100\n",
            "        camel       0.41      0.24      0.30       100\n",
            "          can       0.44      0.43      0.43       100\n",
            "       castle       0.74      0.39      0.51       100\n",
            "  caterpillar       0.35      0.42      0.38       100\n",
            "       cattle       0.42      0.23      0.30       100\n",
            "        chair       0.84      0.57      0.68       100\n",
            "   chimpanzee       0.24      0.77      0.37       100\n",
            "        clock       0.33      0.23      0.27       100\n",
            "        cloud       0.58      0.63      0.61       100\n",
            "    cockroach       0.43      0.77      0.55       100\n",
            "        couch       0.30      0.25      0.27       100\n",
            "         crab       0.59      0.16      0.25       100\n",
            "    crocodile       0.22      0.40      0.28       100\n",
            "          cup       0.51      0.52      0.51       100\n",
            "     dinosaur       0.40      0.29      0.34       100\n",
            "      dolphin       0.36      0.38      0.37       100\n",
            "     elephant       0.24      0.47      0.32       100\n",
            "     flatfish       0.26      0.36      0.30       100\n",
            "       forest       0.40      0.53      0.45       100\n",
            "          fox       0.35      0.30      0.32       100\n",
            "         girl       0.21      0.36      0.27       100\n",
            "      hamster       0.46      0.41      0.43       100\n",
            "        house       0.38      0.40      0.39       100\n",
            "     kangaroo       0.19      0.16      0.17       100\n",
            "     keyboard       0.36      0.57      0.44       100\n",
            "         lamp       0.31      0.25      0.28       100\n",
            "   lawn_mower       0.61      0.61      0.61       100\n",
            "      leopard       0.42      0.31      0.36       100\n",
            "         lion       0.33      0.52      0.41       100\n",
            "       lizard       0.21      0.21      0.21       100\n",
            "      lobster       0.27      0.13      0.17       100\n",
            "          man       0.22      0.28      0.25       100\n",
            "   maple_tree       0.52      0.50      0.51       100\n",
            "   motorcycle       0.70      0.62      0.66       100\n",
            "     mountain       0.34      0.65      0.45       100\n",
            "        mouse       0.19      0.12      0.15       100\n",
            "     mushroom       0.28      0.20      0.23       100\n",
            "     oak_tree       0.62      0.70      0.66       100\n",
            "       orange       0.64      0.61      0.62       100\n",
            "       orchid       0.45      0.65      0.53       100\n",
            "        otter       0.17      0.10      0.13       100\n",
            "    palm_tree       0.61      0.52      0.56       100\n",
            "         pear       0.42      0.39      0.40       100\n",
            " pickup_truck       0.45      0.33      0.38       100\n",
            "    pine_tree       0.39      0.43      0.41       100\n",
            "        plain       0.82      0.69      0.75       100\n",
            "        plate       0.44      0.48      0.46       100\n",
            "        poppy       0.45      0.48      0.47       100\n",
            "    porcupine       0.29      0.46      0.36       100\n",
            "       possum       0.15      0.18      0.16       100\n",
            "       rabbit       0.22      0.10      0.14       100\n",
            "      raccoon       0.20      0.22      0.21       100\n",
            "          ray       0.33      0.34      0.33       100\n",
            "         road       0.72      0.63      0.67       100\n",
            "       rocket       0.62      0.58      0.60       100\n",
            "         rose       0.39      0.49      0.43       100\n",
            "          sea       0.55      0.62      0.58       100\n",
            "         seal       0.13      0.22      0.17       100\n",
            "        shark       0.30      0.50      0.38       100\n",
            "        shrew       0.28      0.15      0.20       100\n",
            "        skunk       0.53      0.63      0.57       100\n",
            "   skyscraper       0.73      0.51      0.60       100\n",
            "        snail       0.14      0.17      0.15       100\n",
            "        snake       0.28      0.08      0.12       100\n",
            "       spider       0.36      0.30      0.33       100\n",
            "     squirrel       0.17      0.15      0.16       100\n",
            "    streetcar       0.43      0.44      0.43       100\n",
            "    sunflower       0.87      0.69      0.77       100\n",
            " sweet_pepper       0.41      0.37      0.39       100\n",
            "        table       0.50      0.24      0.32       100\n",
            "         tank       0.48      0.54      0.51       100\n",
            "    telephone       0.58      0.29      0.39       100\n",
            "   television       0.51      0.33      0.40       100\n",
            "        tiger       0.36      0.38      0.37       100\n",
            "      tractor       0.45      0.41      0.43       100\n",
            "        train       0.27      0.37      0.31       100\n",
            "        trout       0.48      0.41      0.44       100\n",
            "        tulip       0.32      0.24      0.27       100\n",
            "       turtle       0.21      0.20      0.20       100\n",
            "     wardrobe       0.70      0.72      0.71       100\n",
            "        whale       0.38      0.62      0.47       100\n",
            "  willow_tree       0.42      0.26      0.32       100\n",
            "         wolf       0.26      0.36      0.31       100\n",
            "        woman       0.26      0.05      0.08       100\n",
            "         worm       0.31      0.41      0.35       100\n",
            "\n",
            "     accuracy                           0.39     10000\n",
            "    macro avg       0.41      0.39      0.38     10000\n",
            " weighted avg       0.41      0.39      0.38     10000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9M5BmaK1XG3F"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kRx8qmNdUnNr"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FVvVFGtHUwFX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
